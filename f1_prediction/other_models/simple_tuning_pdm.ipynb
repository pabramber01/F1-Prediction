{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is podium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependencies used are as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor, XGBRanker\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.custom_cvs import VariableTimeSeriesSplit\n",
    "from utils.custom_scorers import balanced_accuracy_score, balanced_accuracy_ranker\n",
    "\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with the tuning of the model that predicts the podium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../assets/data/processed/other_models.csv\")\n",
    "\n",
    "mid_rc = df.groupby(\"raceYear\")[\"raceRound\"].max().to_numpy() // 2\n",
    "get_half = lambda x: f'{x[\"raceYear\"]}{x[\"raceRound\"] <= mid_rc[x[\"raceYear\"] - 2006]}'\n",
    "instances_per_half = df.apply(get_half, axis=1).value_counts(sort=False).to_numpy()\n",
    "\n",
    "n_splits = len(instances_per_half) - 10\n",
    "max_train_size = [instances_per_half[i : 10 + i].sum() for i in range(n_splits)]\n",
    "test_size = instances_per_half[10:].tolist()\n",
    "tscv = VariableTimeSeriesSplit(\n",
    "    n_splits=n_splits, max_train_size=max_train_size, test_size=test_size\n",
    ")\n",
    "\n",
    "podiums = df[df[\"positionFinal\"].isin([1, 2, 3])][\n",
    "    [\"raceYear\", \"raceRound\", \"driverRef\"]\n",
    "]\n",
    "podiums = podiums.groupby(by=[\"raceYear\", \"raceRound\"]).agg({\"driverRef\": \",\".join})\n",
    "\n",
    "X = pd.read_csv(\"../assets/data/processed/other_models_X.csv\")\n",
    "y = df.merge(podiums, how=\"left\", on=[\"raceYear\", \"raceRound\"], suffixes=(\"\", \"Podium\"))\n",
    "y = y.apply(lambda x: int(x[\"driverRef\"] in x[\"driverRefPodium\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier: 0.7874969518034617 with {'subsample': 0.75, 'reg_lambda': 10,\n",
      "\t'reg_alpha': 3, 'n_estimators': 75, 'min_child_weight': 5, 'max_depth': 3,\n",
      "\t'learning_rate': 0.2, 'gamma': 0.5, 'colsample_bytree': 0.75}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    learning_rate=[0.01, 0.1, 0.2],\n",
    "    n_estimators=[50, 75, 150],\n",
    "    max_depth=[3, 5, 10],\n",
    "    min_child_weight=[1, 5, 15, 200],\n",
    "    gamma=[0, 0.5, 0.75, 0.9],\n",
    "    subsample=[0.5, 0.75, 0.9],\n",
    "    colsample_bytree=[0.5, 0.75, 0.9],\n",
    "    reg_alpha=[0, 3, 10],\n",
    "    reg_lambda=[0, 3, 10],\n",
    ")\n",
    "search = RandomizedSearchCV(\n",
    "    XGBClassifier(objective=\"binary:logistic\"),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    n_iter=30,\n",
    ").fit(X, y)\n",
    "output = f\"XGBClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor: 0.7959400063566847 with {'subsample': 0.75, 'reg_lambda': 3, 'reg_alpha':\n",
      "\t0, 'n_estimators': 150, 'min_child_weight': 200, 'max_depth': 10, 'learning_rate': 0.1,\n",
      "\t'gamma': 0.75, 'colsample_bytree': 0.9}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    learning_rate=[0.01, 0.1, 0.2],\n",
    "    n_estimators=[50, 75, 150],\n",
    "    max_depth=[3, 5, 10],\n",
    "    min_child_weight=[1, 5, 15, 200],\n",
    "    gamma=[0, 0.5, 0.75, 0.9],\n",
    "    subsample=[0.5, 0.75, 0.9],\n",
    "    colsample_bytree=[0.5, 0.75, 0.9],\n",
    "    reg_alpha=[0, 3, 10],\n",
    "    reg_lambda=[0, 3, 10],\n",
    ")\n",
    "search = RandomizedSearchCV(\n",
    "    XGBRegressor(objective=\"reg:linear\"),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    n_iter=50,\n",
    ").fit(X, y)\n",
    "output = f\"XGBRegressor: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRanker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRanker: 0.8133024369850297 with {'subsample': 0.9, 'reg_lambda': 3, 'reg_alpha': 10,\n",
      "\t'n_estimators': 75, 'min_child_weight': 200, 'max_depth': 5, 'learning_rate': 0.01,\n",
      "\t'gamma': 0, 'colsample_bytree': 0.75}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    learning_rate=[0.01, 0.1, 0.2],\n",
    "    n_estimators=[50, 75, 150],\n",
    "    max_depth=[3, 5, 10],\n",
    "    min_child_weight=[1, 5, 15, 200],\n",
    "    gamma=[0, 0.5, 0.75, 0.9],\n",
    "    subsample=[0.5, 0.75, 0.9],\n",
    "    colsample_bytree=[0.5, 0.75, 0.9],\n",
    "    reg_alpha=[0, 3, 10],\n",
    "    reg_lambda=[0, 3, 10],\n",
    ")\n",
    "search = RandomizedSearchCV(\n",
    "    XGBRanker(objective=\"rank:pairwise\"),\n",
    "    grid,\n",
    "    scoring=balanced_accuracy_ranker,\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    "    n_iter=50,\n",
    ").fit(X, y)\n",
    "output = f\"XGBRanker: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After viewing several runs, the hyperparameters for each algorithm are as follows\n",
    "\n",
    "- XGBClassifier: 0.7874969518034617 with {'subsample': 0.75, 'reg_lambda': 10, 'reg_alpha': 3, 'n_estimators': 75, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.2, 'gamma': 0.5, 'colsample_bytree': 0.75}\n",
    "- XGBRegressor: 0.7959400063566847 with {'subsample': 0.75, 'reg_lambda': 3, 'reg_alpha': 0, 'n_estimators': 150, 'min_child_weight': 200, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0.75, 'colsample_bytree': 0.9}\n",
    "- XGBRanker: 0.8133024369850297 with {'subsample': 0.9, 'reg_lambda': 3, 'reg_alpha': 10, 'n_estimators': 75, 'min_child_weight': 200, 'max_depth': 5, 'learning_rate': 0.01, 'gamma': 0, 'colsample_bytree': 0.75}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final position in variable interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependencies used are as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.custom_cvs import VariableTimeSeriesSplit\n",
    "from utils.custom_scorers import (\n",
    "    balanced_accuracy_1interval_score,\n",
    "    mean_absolute_1interval_error,\n",
    ")\n",
    "\n",
    "import textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will do the tuning of the model that predicts the final position of each driver at a Â±1 interval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../assets/data/processed/base_model.csv\")\n",
    "\n",
    "instances_per_year = df[\"raceYear\"].value_counts(sort=False)\n",
    "instances_per_half = (\n",
    "    np.array(\n",
    "        list(zip(np.floor(instances_per_year / 2), np.ceil(instances_per_year / 2)))\n",
    "    )\n",
    "    .flatten()\n",
    "    .astype(np.int32)\n",
    ")\n",
    "\n",
    "n_splits = len(instances_per_half) - 10\n",
    "max_train_size = [instances_per_half[i : 10 + i].sum() for i in range(n_splits)]\n",
    "test_size = instances_per_half[10:].tolist()\n",
    "tscv = VariableTimeSeriesSplit(\n",
    "    n_splits=n_splits, max_train_size=max_train_size, test_size=test_size\n",
    ")\n",
    "\n",
    "X = pd.read_csv(\"../assets/data/processed/base_model_X.csv\")\n",
    "y = df[\"positionFinal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier: 0.28718245979609613 with {'metric': 'manhattan', 'n_neighbors':\n",
      "\t101, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    n_neighbors=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 21, 31, 51, 101],\n",
    "    weights=[\"uniform\", \"distance\", None],\n",
    "    metric=[\"euclidean\", \"manhattan\", \"cosine\"],\n",
    ")\n",
    "search = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_1interval_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ").fit(X, y)\n",
    "output = f\"KNeighborsClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 0.3389971896790078 with {'criterion': 'entropy', 'max_depth': 5,\n",
      "\t'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    criterion=[\"gini\", \"entropy\", \"log_loss\"],\n",
    "    splitter=[\"best\", \"random\"],\n",
    "    max_depth=[2, 3, 4, 5, 6, 10, 20],\n",
    ")\n",
    "search = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_1interval_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ").fit(X, y)\n",
    "output = f\"DecisionTreeClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: 0.34932197852652397 with {'criterion': 'gini', 'max_depth': 5,\n",
      "\t'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    n_estimators=[10, 30, 50, 100, 200],\n",
    "    criterion=[\"gini\", \"entropy\", \"log_loss\"],\n",
    "    max_depth=[2, 3, 4, 5, 6, 10, 20],\n",
    ")\n",
    "search = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_1interval_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ").fit(X, y)\n",
    "output = f\"RandomForestClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier: 0.35292989628216903 with {'activation': 'logistic', 'hidden_layer_sizes':\n",
      "\t(50, 25)}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    hidden_layer_sizes=[(100,), (50, 25), (50, 20, 5)],\n",
    "    activation=[\"relu\", \"logistic\"],\n",
    ")\n",
    "search = GridSearchCV(\n",
    "    MLPClassifier(),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_1interval_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ").fit(X, y)\n",
    "output = f\"MLPClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After viewing several runs, the hyperparameters for each algorithm are as follows\n",
    "\n",
    "- KNeighborsClassifier: 0.2863537094218912 with {'metric': 'manhattan', 'n_neighbors': 101, 'weights': 'uniform'}\n",
    "- DecisionTreeClassifier: 0.34112213333804237 with {'criterion': 'gini', 'max_depth': 4, 'splitter': 'best'}\n",
    "- RandomForestClassifier: 0.3479073809187445 with {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 200}\n",
    "- MLPClassifier: 0.3586966547762002 with {'activation': 'logistic', 'hidden_layer_sizes': (50, 25)}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is podium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependencies used are as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.custom_cvs import VariableTimeSeriesSplit\n",
    "from utils.custom_scorers import balanced_accuracy_score\n",
    "\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue with the tuning of the model that predicts the podium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../assets/data/processed/adding_data.csv\")\n",
    "\n",
    "mid_rc = df.groupby(\"raceYear\")[\"raceRound\"].max().to_numpy() // 2\n",
    "get_half = lambda x: f'{x[\"raceYear\"]}{x[\"raceRound\"] <= mid_rc[x[\"raceYear\"] - 2006]}'\n",
    "instances_per_half = df.apply(get_half, axis=1).value_counts(sort=False).to_numpy()\n",
    "\n",
    "n_splits = len(instances_per_half) - 10\n",
    "max_train_size = [instances_per_half[i : 10 + i].sum() for i in range(n_splits)]\n",
    "test_size = instances_per_half[10:].tolist()\n",
    "tscv = VariableTimeSeriesSplit(\n",
    "    n_splits=n_splits, max_train_size=max_train_size, test_size=test_size\n",
    ")\n",
    "\n",
    "podiums = df[df[\"positionFinal\"].isin([1, 2, 3])][\n",
    "    [\"raceYear\", \"raceRound\", \"driverRef\"]\n",
    "]\n",
    "podiums = podiums.groupby(by=[\"raceYear\", \"raceRound\"]).agg({\"driverRef\": \",\".join})\n",
    "\n",
    "X = pd.read_csv(\"../assets/data/processed/adding_data_X.csv\")\n",
    "y = df.merge(podiums, how=\"left\", on=[\"raceYear\", \"raceRound\"], suffixes=(\"\", \"Podium\"))\n",
    "y = y.apply(lambda x: int(x[\"driverRef\"] in x[\"driverRefPodium\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier: 0.7380751972783101 with {'metric': 'cosine', 'n_neighbors': 6,\n",
      "\t'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    n_neighbors=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 21, 31, 51, 101],\n",
    "    weights=[\"uniform\", \"distance\", None],\n",
    "    metric=[\"euclidean\", \"manhattan\", \"cosine\"],\n",
    ")\n",
    "search = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ").fit(X, y)\n",
    "output = f\"KNeighborsClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 0.783119412032717 with {'criterion': 'entropy', 'max_depth': 4,\n",
      "\t'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    criterion=[\"gini\", \"entropy\", \"log_loss\"],\n",
    "    splitter=[\"best\", \"random\"],\n",
    "    max_depth=[2, 3, 4, 5, 6, 10, 20],\n",
    ")\n",
    "search = GridSearchCV(\n",
    "    DecisionTreeClassifier(),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ").fit(X, y)\n",
    "output = f\"DecisionTreeClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: 0.7665285291056751 with {'criterion': 'gini', 'max_depth': 10,\n",
      "\t'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    n_estimators=[10, 30, 50, 100, 200],\n",
    "    criterion=[\"gini\", \"entropy\", \"log_loss\"],\n",
    "    max_depth=[2, 3, 4, 5, 6, 10, 20],\n",
    ")\n",
    "search = GridSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ").fit(X, y)\n",
    "output = f\"RandomForestClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier: 0.7845751288896926 with {'activation': 'logistic', 'hidden_layer_sizes':\n",
      "\t(50, 20, 5)}\n"
     ]
    }
   ],
   "source": [
    "grid = dict(\n",
    "    hidden_layer_sizes=[(100,), (50, 25), (50, 20, 5)],\n",
    "    activation=[\"relu\", \"logistic\"],\n",
    ")\n",
    "search = GridSearchCV(\n",
    "    MLPClassifier(),\n",
    "    grid,\n",
    "    scoring=make_scorer(balanced_accuracy_score),\n",
    "    cv=tscv,\n",
    "    n_jobs=-1,\n",
    ").fit(X, y)\n",
    "output = f\"MLPClassifier: {search.best_score_} with {search.best_params_}\"\n",
    "print(\"\\n\".join(textwrap.wrap(output, 88, subsequent_indent=\"\\t\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After viewing several runs, the hyperparameters for each algorithm are as follows\n",
    "\n",
    "- KNeighborsClassifier: 0.7380751972783101 with {'metric': 'cosine', 'n_neighbors': 6, 'weights': 'distance'}\n",
    "- DecisionTreeClassifier: 0.783119412032717 with {'criterion': 'entropy', 'max_depth': 4, 'splitter': 'best'}\n",
    "- RandomForestClassifier: 0.7665285291056751 with {'criterion': 'gini', 'max_depth': 10, 'n_estimators': 200}\n",
    "- MLPClassifier: 0.7845751288896926 with {'activation': 'logistic', 'hidden_layer_sizes': (50, 20, 5)}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
